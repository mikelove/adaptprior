---
title: "Adaptive priors for genomic data"
author: Michael Love
bibliography: library.bib
output:
  revealjs::revealjs_presentation:
    controls: false
    progress: false
    center: true
    transition: "none"
    self_contained: false
---

## Work in collaboration with

* Anqi Zhu (UNC-CH)
* Joseph Ibrahim (UNC-CH)

This talk: [mikelove.github.io/adaptprior](https://mikelove.github.io/adaptprior)

```{r include=FALSE}
knitr::opts_chunk$set(cache=TRUE,
  echo=FALSE, results="hide",
  message=FALSE, warning=FALSE)
```

<style>
.container{
    display: flex;
}
.col{
    flex: 1;
}
</style>

## Aims and activity of the [Love lab](https://mikelove.github.io)

<img height=100 src="rlogo.png"> <img height=100 src="bioconductorlogo.jpg">

* Robust, extensible software for genomic data science
* Statistical method development
* Reproducible research and workflows
* Collaborations: Genetics, Biology, CS, Statistics

## Our starting point

* In genomic data analysis, we often begin with plots
* Crucial for high dimensional analysis:
    - effect size over mean
	- within-group variance over mean
	- systematic variation (boxplots, PCA)

## Gene expression

* Many collaborations around gene expression:
    - adipose tissue (T2D)*
	- progenitor neurons (autism, schizophrenia)*
	- colon (IBD)*
	- macrophage (arthritis)*
	- breast tumor
    - upper airway and lung (HIV)
* Often, a *counting* technology
    - Sequencing of cDNA fragments
	- Nanostring
	
\* also interested in chromatin accessibility or structure

## Often, interest in log fold change 

Expression of $G$ genes, 5 replicates in 2 groups:

$$[X_{g1}, \dots, X_{g5}] \quad \textrm{vs} \quad [Y_{g1}, \dots, Y_{g5}]$$

$$ E(X_{gi}) = \mu_{gX} $$

$$ E(Y_{gi}) = \mu_{gY} $$

$$ \beta_g \equiv \log_2 \left( \frac{\mu_{gY}}{\mu_{gX}} \right) $$

## Complexities

* Counts $X_{gi}$ and $Y_{gi}$ are actually estimated [1]
* Technical artifacts: per-sample scaling factor / offset [2]
* Negative Binomial widely used
    - dispersion parameter must be estimated [3]
	- zero component for highly amplified data [4]

<small>
[1] [@Soneson2015], [2] [@Anders2010], <br/>
[3] [@Love2014], [4] [@Berge2018]
</small>

## Effect size over mean ("MA" or Bland-Altman)

```{r}
suppressPackageStartupMessages(library(DESeq2))
m <- 10
n <- 2500
dmr <- function(x) 4/x + exp(rnorm(n,log(.01),2))
set.seed(1)
dds <- makeExampleDESeqDataSet(m=m, n=n, betaSD=.5,
                               interceptMean=5, interceptSD=4,
                               dispMeanRel=dmr)
keep <- rowSums(counts(dds) >= 5) >= 3
keep <- keep & rowMeans(counts(dds)) < 1e4
dds <- dds[keep,]
dds <- DESeq(dds)
normal <- lfcShrink(dds, coef=2, type="normal")$log2FoldChange
grp1 <- rowMeans(counts(dds)[,1:(m/2)])
grp2 <- rowMeans(counts(dds)[,(m/2 + 1):m])
```

```{r ma}
dat <- data.frame(log10mean=log10(.5 * (grp1 + grp2)),
                  log2FC=log2(grp2/grp1),
                  pc1=log2(grp2+1) - log2(grp1+1),
                  pc5=log2(grp2+5) - log2(grp1+5),
                  normal=normal,
                  true=mcols(dds)$trueBeta)
dat$category <- factor(ceiling(dat$log10mean))
levels(dat$category) <- c("<10","<100","<1,000","<10,000")
library(ggplot2)
big.text <- theme(axis.text=element_text(size=14),
                  axis.title=element_text(size=18),
                  legend.text=element_text(size=14),
                  legend.title=element_text(size=16))
ggplot(dat, aes(x=log10mean, y=log2FC, col=category)) +
  geom_point(alpha=.3,size=2) +
  ylim(-5,5) + geom_hline(yintercept=0, col="black") + big.text
```

## Estimate over truth

```{r scatter}
ggplot(dat, aes(x=true, y=log2FC, col=category)) + geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  ylim(-3,3) + big.text
```

## Faceted by mean

```{r facet}
ggplot(dat, aes(x=true, y=log2FC, col=category)) + geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") + facet_wrap(~category) +
  ylim(-3,3) + big.text
```

## Pseudocount 1

```{r facet1}
yvar <- "pc1"
ggplot(dat, aes_string(x="true", y=yvar, col="category")) +
  geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  facet_wrap(~category) + ylim(-3,3) + big.text
```

## Pseudocount 5

```{r facet5}
yvar <- "pc5"
ggplot(dat, aes_string(x="true", y=yvar, col="category")) +
  geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  facet_wrap(~category) + ylim(-3,3) + big.text
```

## Normal prior

```{r facetNormal}
yvar <- "normal"
ggplot(dat, aes_string(x="true", y=yvar, col="category")) +
  geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  facet_wrap(~category) + ylim(-3,3) + big.text
```

## Pseudocount 5

```{r scatter5}
ggplot(dat, aes(x=true, y=pc5, col=category)) + geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") + ylim(-3,3) + big.text
```

## Normal prior

```{r scatterNormal}
ggplot(dat, aes(x=true, y=normal, col=category)) + geom_point(alpha=.3,size=2) +
  geom_abline(intercept=0, slope=1, col="black") + ylim(-3,3) + big.text
```

## What do we see

<div class="container">

<div class="col">
<img width=400 src="index_files/figure-revealjs/scatterNormal-1.png">
</div>

<div class="col">
<br/>

* Reduced variance
* Genes can be ranked
* Moderate bias

</div>
</div>

## Simplify statistical routines

```{r echo=TRUE, eval=FALSE}
# import the counts
se <- tximeta(samples)
# create gene-level summarizes
gse <- summarizeToGene(se)
# make a dataset
dds <- DESeqDataSet(se, ~batch + condition)
# offsets, dispersion, MLE log2FC
dds <- DESeq(dds)
# shrinkage estimation
res <- lfcShrink(dds, coef=2)
```


---

### References

<font size="-1">
