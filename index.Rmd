---
title: "Adaptive priors for estimating effect size with genomic data"
author: |
  | Michael Love
  | Dept. of Biostatistics
  | Dept. of Genetics
  | UNC-Chapel Hill
bibliography: library.bib
csl: apa.csl
output: 
  revealjs::revealjs_presentation:
    highlight: tango
    center: true
    transition: "none"
    self_contained: false
---

## Work in collaboration with

* Anqi Zhu (UNC-CH)
* Joseph Ibrahim (UNC-CH)

```{r include=FALSE}
knitr::opts_chunk$set(cache=TRUE,
  echo=FALSE, results="hide",
  message=FALSE, warning=FALSE)
```

<style>
.container{
    display: flex;
}
.col{
    flex: 1;
}
</style>

## Aims and activity of the [Love lab](https://mikelove.github.io)

<img height=100 src="rlogo.png"> <img height=100 src="bioconductorlogo.jpg">

* Robust, extensible software for genomic data science
* Statistical method development
* Reproducible research and workflows
* Collaborations: Genetics, Biology, CS, Statistics

## Our starting point

* In genomic data analysis, we often begin with plots
* Crucial for high dimensional analysis:
    - effect size over mean
	- within-group variance over mean
	- systematic variation (boxplots, PCA)

## Gene expression

* Many collaborations around gene expression:
    - adipose tissue (T2D)*
	- progenitor neurons (autism, schizophrenia)*
	- colon (IBD)*
	- macrophage (arthritis)*
	- breast tumor
    - upper airway and lung (HIV)
* Often, a *counting* technology
    - Sequencing of cDNA fragments
	- Nanostring
	
\* also interested in chromatin accessibility or structure

## Often, interested in log fold change 

Expression of $G$ genes, 5 replicates in 2 groups:

$$[X_{g1}, \dots, X_{g5}] \quad \textrm{vs} \quad [Y_{g1}, \dots, Y_{g5}]$$

$$ E(X_{gi}) = \mu_{gX} $$

$$ E(Y_{gi}) = \mu_{gY} $$

$$ \beta_g \equiv \log_2 \left( \frac{\mu_{gY}}{\mu_{gX}} \right) $$

## Complexities

> * Counts $X_{gi}$ and $Y_{gi}$ are actually estimated [1-3]
> * Technical artifacts: per-sample scaling factor / offset [4-5]
> * Negative Binomial widely used
>     - dispersion parameter must be estimated [6-8]
>     - zero component for highly amplified data [9]

<small>
**References** <br/>
[1] Issue of DGE [@Trapnell2013] <br/>
[2] Bias models [@Patro2017], <br/>
[3] Isoform offset [@Soneson2015], <br/>
[4] TMM [@Robinson2010], <br/>
[5] Median ratio [@Anders2010], <br/>
[6] edgeR GLM [@McCarthy2012], <br/>
[7] DSS [@Wu2012], <br/>
[8] DESeq2 [@Love2014], <br/>
[9] ZI weights [@Berge2018]
</small>

## Effect size in simulated data

* Simulation of over-dispersed count data 
* 2500 "genes", 5 vs 5 replicates

## Effect size over mean ("MA" or Bland-Altman)

```{r}
suppressPackageStartupMessages(library(DESeq2))
m <- 10
n <- 2500
dmr <- function(x) 4/x + exp(rnorm(n,log(.01),2))
set.seed(1)
dds <- makeExampleDESeqDataSet(m=m, n=n, betaSD=.5,
                               interceptMean=5, interceptSD=4,
                               dispMeanRel=dmr)
keep <- rowSums(counts(dds) >= 5) >= 3
keep <- keep & rowMeans(counts(dds)) < 1e4
dds <- dds[keep,]
dds <- DESeq(dds)
normal <- lfcShrink(dds, coef=2, type="normal")$log2FoldChange
grp1 <- rowMeans(counts(dds)[,1:(m/2)])
grp2 <- rowMeans(counts(dds)[,(m/2 + 1):m])
```

```{r ma}
dat <- data.frame(log10mean=log10(.5 * (grp1 + grp2)),
                  log2FoldChange=log2(grp2/grp1),
                  pseudocount.1=log2(grp2+1) - log2(grp1+1),
                  pseudocount.5=log2(grp2+5) - log2(grp1+5),
                  Normal.prior=normal,
                  true=mcols(dds)$trueBeta)
dat$category <- factor(ceiling(dat$log10mean))
levels(dat$category) <- c("<10","<100","<1,000","<10,000")
library(ggplot2)
big.text <- theme(axis.text=element_text(size=14),
                  axis.title=element_text(size=18),
                  legend.text=element_text(size=14),
                  legend.title=element_text(size=16))
rgb2 <- function(x,y,z) rgb(x,y,z,maxColorValue=255)
my.cols <- scale_color_manual(values=cols)
cols <- c(rgb2(230,159,0),rgb2(86,180,233),rgb2(0,158,115),rgb2(0,114,178))
ggplot(dat, aes(x=log10mean, y=log2FoldChange, col=category)) +
  geom_point(size=2) + ylim(-5,5) + geom_hline(yintercept=0, col="black") +
  my.cols + big.text
```

## Estimate over truth

```{r scatter}
ggplot(dat, aes(x=true, y=log2FoldChange, col=category)) + geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  ylim(-3,3) + my.cols + big.text
```

## Faceted by mean

```{r facet}
ggplot(dat, aes(x=true, y=log2FoldChange, col=category)) + geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") + facet_wrap(~category) +
  ylim(-3,3) + my.cols + big.text
```

## Pseudocount 1

```{r facet1}
yvar <- "pseudocount.1"
ggplot(dat, aes_string(x="true", y=yvar, col="category")) +
  geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  facet_wrap(~category) + ylim(-3,3) + my.cols + big.text
```

## Pseudocount 5

```{r facet5}
yvar <- "pseudocount.5"
ggplot(dat, aes_string(x="true", y=yvar, col="category")) +
  geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  facet_wrap(~category) + ylim(-3,3) + my.cols + big.text
```

## Normal prior

```{r facet-normal}
yvar <- "Normal.prior"
ggplot(dat, aes_string(x="true", y=yvar, col="category")) +
  geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") +
  facet_wrap(~category) + ylim(-3,3) + my.cols + big.text
```

## Pseudocount 5

```{r scatter5}
ggplot(dat, aes(x=true, y=pseudocount.5, col=category)) +
  geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") + ylim(-3,3) +
  my.cols + big.text
```

## Normal prior

```{r scatter-normal}
ggplot(dat, aes(x=true, y=Normal.prior, col=category)) +
  geom_point(size=2) +
  geom_abline(intercept=0, slope=1, col="black") + ylim(-3,3) +
  my.cols + big.text
```

## What do we see

<div class="container">

<div class="col">
<img width=400 src="index_files/figure-revealjs/scatter-normal-1.png">
</div>

<div class="col">
<br/>

* Reduced variance
* Genes can be ranked
* Moderate bias

</div>
</div>

## Simplify statistical routines

```{r echo=TRUE, eval=FALSE}
# import the counts
se <- tximeta(samples)
gse <- summarizeToGene(se)

# make a dataset
dds <- DESeqDataSet(gse, ~batch + condition)

# variance stabilization for PCA, etc.
vsd <- vst(dds)

# scaling factors, dispersion, MLE LFC
dds <- DESeq(dds)

# shrinkage estimation
res <- lfcShrink(dds, coef=3)
```

## Look at real LFC distribution

> * Highly replicated yeast dataset [@Schurch2016]
> * 42 vs 44 biological replicates
> * $\Delta snf2$ mutant
>     - Catalytic component of the SWI/SNF complex
>     - Chromatin-remodeling 
>     - \+ and - regulation of a large number of genes

## LFC in highly replicated yeast

```{r yeast-ma, echo=FALSE}
load("yeast_res.rda")
res.df <- as.data.frame(res)
res.df$log10mean <- log10(res.df$baseMean)
res.df <- subset(res.df, log10mean > -1)
res.df$FDR.05 <- res.df$padj < .05
res.df$ymin <- with(res.df, log2FoldChange - 2*lfcSE)
res.df$ymax <- with(res.df, log2FoldChange + 2*lfcSE)
ggplot(res.df, aes(log10mean, log2FoldChange, col=FDR.05)) +
  geom_point(alpha=.3) +
  geom_hline(yintercept=0, col="red") +
  scale_color_manual(values=c("black", "red")) + big.text
```

## LFC with 2x SE (1700 black, 5100 red)

```{r yeast-ma2, echo=FALSE, out.width=630, out.height=450}
ggplot(res.df, aes(log10mean, log2FoldChange, col=FDR.05, ymin=ymin, ymax=ymax)) +
  geom_point(alpha=.3) + geom_errorbar(alpha=.3) + 
  geom_hline(yintercept=0, col="red") +
  coord_cartesian(xlim=c(0,5), ylim=c(-2,2)) + 
  scale_color_manual(values=c("black", "red")) + big.text
```

\* Actually, $y=0$ not trivial to determine here

## How the Normal prior is implemented 

> * Consider all of MLE coefficients, $\hat{\beta}_g$
> * Want to adapt prior to the spread of these
> * Inverse weight by variance of log counts, $1/\bar{\mu}_g + \alpha_{tr}(\bar{\mu}_g)$
> * Normal has thin tails
> * Pick a Normal to match the upper 5% *weighted* quantile

[@Love2014]

## Alternative adaptive priors with heavy tails

<img width=300 src="andean_cat.jpg">

> * ashr [@Stephens2016]
>     - $\pi_0 \delta_0 + \sum_{k=1}^K \pi_k N(\cdot; 0, \sigma_k^2)$
>     - $\sigma_1, \dots, \sigma_k$ a large, dense, fixed grid
> * apeglm [@Zhu2018]
>     - Cauchy prior with scale parameter $S$

## Previous work on LFC shrinkage in RNA-seq

* ShrinkBayes [@vandewiel2012;@vandewiel2014]
    - shrinkage of many parameters simultaneously
    - non-equal mixture proportions for + and - effects
	- spike + parametric,  spike + non-parametric
    - Integrated Nested Laplace Approximation `INLA`

## Method details

> * ashr:
>     - set $\sigma_k$ grid based on min $\hat{s}_g$ and max $\hat{\beta}_g^2 - \hat{s}_g^2$
>     - estimate $\pi_k$ using $\hat{\beta}_g$ and $\hat{s}_g$
>     - $P(\hat{\beta}_g | \beta_g, \hat{s}_g) = N(\hat{\beta}_g; \beta_g, \hat{s}_g^2)$
>     - return the posterior mean, SD, FSR
> * apeglm: 
>     - set the scale $S$ of Cauchy using $\hat{\beta}_g$ and $\hat{s}_g$
>     - shrink only one coefficient at a time
>     - use data $Y_g$, parameters $\theta_g$, likelihood (NB, ZINB, etc.)
>     - return the posterior mode, SD, profile posterior intervals

## Connection to `bayesglm`

> * Uses a 2.5 scale Cauchy prior on non-constant coefficients
> * Posterior mode and SE via an approximate EM within IRLS
> * "*want something better than the unstable estimates produced by the current default - maximum likelihood*"
> * "*[Cauchy] allows for occasional large coefficients while still performing a reasonable amount of shrinkage for coefficients near zero*"

[@Gelman2008]

## Connection to `bayesglm`

Cauchy can be modeled as a mixture of Normals:

$$ \beta \sim N(\mu, \sigma^2) $$

$$ \sigma^2 \sim \textrm{Scale-inv-} \chi^2(\nu, S^2) $$

* Within IRLS, perform an EM step
* Treat $\beta$ as missing data, estimate $\sigma$

[@Gelman2008]

## `apeglm` implementation

**A**pproximate **P**osterior **E**stimation for **GLM**

* Prior fit to $\hat{\beta}_g$ and $\hat{s}_g$, details on next slide
* Treat dispersion parameter as fixed
* C++ version of L-BFGS-B to obtain posterior mode [1]
* `optim` to obtain Hessian for Laplace approximation [2]
* [1] takes < 1 s, [2] takes ~3 s, over e.g. 10k genes

---

Solve for $A$ in the following [@EfronMorris]

$A = \sum_{g=1}^G (\hat{\beta}_g^2 - e_g^2) I_g(A) \, / \, \sum_{g=1}^G I_g(A)$

$I_g(a) \equiv 1/[2(a + e_g^2)^2]$

Motivated by the following hierarchical model:

$$ \hat{\beta}_g \sim N(\beta_g, e_g^2) $$

$$ \beta_g \sim N(0, A) $$

> 1. We plug in $\hat{s}_g^2$ for $e_g^2$
> 2. We use $S = \sqrt{A}$ to scale a *Cauchy* not a *Normal* prior

## Prior scale & False Sign Rate (FSR)

<img src="adaptive_fsr.png">

## Prior scale & estimation error

<img src="adaptive_eif.png">

## Prior scale & estimation error (example)

<img src="adaptive_eif_problem.png">

## Return to yeast example: 3 vs 3 replicates

## Yeast with Normal prior

```{r echo=FALSE}
load("yeast_res.rda")
load("yeast_dds.rda")
idx <- c(which(dds$condition=="WT")[1:3],
         which(dds$condition=="mut")[1:3])
dds2 <- dds[,idx]
dds2 <- DESeq(dds2)
res2 <- lfcShrink(dds2, coef=2, type="normal")
sub.df <- data.frame(true=res$log2FoldChange,
                     Normal.prior=res2$log2FoldChange,
                     mean=res$baseMean)
cleanIt <- function(sub.df) {
  sub.df <- sub.df[!is.na(sub.df$true),]
  sub.df$type <- factor(ifelse(abs(sub.df$true) < 2, "small.LFC",
                        ifelse(sub.df$mean < 20, "small.mean",
                               "large.mean")),
                        c("small.LFC","small.mean","large.mean"))
  sub.df
}
```

```{r yeast-normal, echo=FALSE}
yeast_x_axis <- scale_x_continuous(breaks=(-4:2) * 2, limits=c(-8,4))
yeast_y_axis <- scale_y_continuous(breaks=-4:2 * 2, limits=c(-8,4))
sub.df <- cleanIt(sub.df)
ggplot(sub.df, aes(true, Normal.prior, col=type)) +
  geom_point(alpha=.3, size=3) +
  geom_abline(slope=1, intercept=0, col="red") +
  yeast_x_axis + yeast_y_axis + 
  scale_color_manual(values=c("black", "orange3", "blue")) + big.text
```

## Yeast with apeglm

```{r yeast-ape, echo=FALSE}
res2 <- lfcShrink(dds2, coef=2, type="apeglm")
sub.df <- data.frame(true=res$log2FoldChange,
                     Cauchy.prior=res2$log2FoldChange,
                     mean=res$baseMean)
sub.df <- cleanIt(sub.df)
ggplot(sub.df, aes(true, Cauchy.prior, col=type)) +
  geom_point(alpha=.3, size=3) +
  geom_abline(slope=1, intercept=0, col="red") +
  yeast_x_axis + yeast_y_axis + 
  scale_color_manual(values=c("black", "orange3", "blue")) + big.text
```

## Yeast with ashr

```{r yeast-ashr, echo=FALSE}
res2 <- lfcShrink(dds2, coef=2, type="ashr")
sub.df <- data.frame(true=res$log2FoldChange,
                     ashr.prior=res2$log2FoldChange,
                     mean=res$baseMean)
sub.df <- cleanIt(sub.df)
ggplot(sub.df, aes(true, ashr.prior, col=type)) +
  geom_point(alpha=.3, size=3) +
  geom_abline(slope=1, intercept=0, col="red") +
  yeast_x_axis + yeast_y_axis + 
  scale_color_manual(values=c("black", "orange3", "blue")) + big.text
```

## Yeast results: 3 and 5 replicates per group

<img width=750 src="yeast.png">

## Simulation: 5 and 10 replicates per group

<img width=750 src="sim_b.png">

## Simulation: 30 and 50 replicates per group

<img width=750 src="sim_largesize_b.png">

## Problem case for apeglm

---

```{r echo=FALSE}
m <- 4
n <- 3200
dmr <- function(x) 1/x + exp(rnorm(n,log(.05),1))
set.seed(1)
betaSD <- rep(c(0,1),c(3000,200))
dds <- makeExampleDESeqDataSet(m=m, n=n, betaSD=betaSD,
                               interceptMean=5, interceptSD=4,
                               dispMeanRel=dmr)
mcols(dds)$betaSD <- betaSD
keep <- rowSums(counts(dds) >= 5) >= 3
keep <- keep & rowMeans(counts(dds)) < 1e4
dds <- dds[keep,]
dds <- DESeq(dds, fitType="mean")
apeglm <- lfcShrink(dds, coef=2, type="apeglm")$log2FoldChange
ashr <- lfcShrink(dds, coef=2, type="ashr")$log2FoldChange
dat <- data.frame(log10mean=rep(log10(mcols(dds)$baseMean),2),
                  estimate=c(apeglm,ashr),
                  method=rep(c("apeglm","ashr"),each=nrow(dds)),
                  true=rep(mcols(dds)$trueBeta,2),
                  category=factor(paste0("betaSD:",rep(mcols(dds)$betaSD,2))))
```

```{r apeglm-limit, echo=FALSE, fig.width=7, fig.height=3}
ggplot(dat, aes(x=true, y=estimate, col=category)) +
  geom_point(alpha=.3,size=2) +
  geom_abline(slope=1, intercept=0, col="black") +
  scale_color_manual(values=c("black", "blue")) + 
  big.text + facet_wrap(~method) + ggtitle("apeglm limitation: n=2 vs 2, spike at 0")
```

```{r apeglm-limit2, echo=FALSE, fig.width=7, fig.height=3}
ggplot(dat, aes(x=log10mean, y=estimate, col=category)) +
  geom_point(alpha=.3,size=2) +
  big.text + facet_wrap(~method) +
  scale_color_manual(values=c("black", "blue")) + 
  ggtitle("apeglm limitation: n=2 vs 2, spike at 0")
```

---

**Paper and software**

* [apeglm preprint](https://doi.org/10.1101/303255) on bioRxiv
  (accepted at *Bioinformatics*)
* `lfcShrink(dds, coef=2, type="apeglm")`
* `lfcShrink(dds, coef=2, type="ashr")`

**Acknowledgments**

* Work by **Anqi Zhu** and Joseph Ibrahim
* Comments from Wolfgang Huber and Cecile Le Sueur 
* Funding:
    - MIL - R01 HG009125, P01 CA142538, P30 ES010126
    - JGI and AZ - R01 GM070335 and P01 CA142538

<!--
## Connection to Bayesian methods

* baySeq
* ShrinkBayes

## Connection to dispersion prior

* DSS
* DESeq2

## Student's t as dispersion prior

* new paper
-->

---

<font size="-2">

